{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjcU2NRzxkV9"
      },
      "source": [
        "# Week 2 - Research Guide: Key Technologies for Fun Response Mode Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXNN-MXF6Q6T"
      },
      "source": [
        "##Take a moment to reasearch the following Terms:\n",
        "\n",
        "\n",
        "1. LangChain\n",
        "2. FAISS\n",
        "3. RAG\n",
        "4. Embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8mYx-8R6FMQ"
      },
      "source": [
        "---\n",
        "\n",
        "### LangChain, FAISS, RAG & Embeddings\n",
        "\n",
        "---\n",
        "\n",
        "## ü¶ú **LangChain**\n",
        "\n",
        "### **What is LangChain?**\n",
        "LangChain is a framework for developing applications powered by large language models (LLMs). LangChain simplifies every stage of the LLM application lifecycle by providing modular components that make building AI applications much easier.\n",
        "\n",
        "### **Key Features & Capabilities:**\n",
        "- **Modular Architecture**: LangChain's power lies in its modular architecture - you can mix and match components\n",
        "- **Tool Integration**: Connect LLMs to APIs, databases, search engines, and external services\n",
        "- **Memory Management**: It offers complete memory management, tool-chain organization, agent regulation, and context retention integration into one unified structure\n",
        "- **Multi-Agent Systems**: LangChain has solidified itself as the go-to framework for building sophisticated, autonomous multi-agent systems\n",
        "\n",
        "### **Why Use LangChain for Chatbots?**\n",
        "- **Chain Different Operations**: Link together prompts, models, and tools in sequence\n",
        "- **Context Retention**: Usually, whenever you request something from a model, it does not retain any information after providing the response - LangChain fixes this\n",
        "- **Real-time Data Access**: Connect your chatbot to live data sources\n",
        "- **Easy Integration**: Works with OpenAI, Anthropic, Google, and many other AI providers\n",
        "\n",
        "### **LangChain in 2025:**\n",
        "The question now is: Is LangChain still needed in 2025? The answer is **YES** - it's more relevant than ever with enhanced features like:\n",
        "- **LangGraph**: For building complex, stateful agent workflows\n",
        "- **LangSmith**: For debugging and monitoring AI applications\n",
        "- **Better Documentation**: Improved learning resources and examples\n",
        "\n",
        "---\n",
        "\n",
        "## üîç **FAISS (Facebook AI Similarity Search)**\n",
        "\n",
        "### **What is FAISS?**\n",
        "Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM\n",
        "\n",
        "### **Key Features:**\n",
        "- **Lightning Fast**: We've built nearest-neighbor search implementations for billion-scale data sets that are some 8.5x faster than the previous reported state-of-the-art\n",
        "- **Memory Efficient**: Some of the methods, like those based on binary vectors and compact quantization codes, solely use a compressed representation of the vectors and do not require to keep the original vectors\n",
        "- **GPU Acceleration**: Faiss supports GPU acceleration, significantly enhancing the speed of vector operations and making it suitable for real-time applications\n",
        "- **Scalable**: Can handle millions to billions of vectors\n",
        "\n",
        "### **Why Use FAISS in Chatbots?**\n",
        "- **Fast Document Retrieval**: Quickly find the most relevant information from your knowledge base\n",
        "- **Similarity Search**: Find documents similar to user queries in milliseconds\n",
        "- **Memory Optimization**: Faiss focuses on methods that compress the original vectors, because they're the only ones that scale to data sets of billions of vectors\n",
        "- **Easy Integration**: The integration lives in the langchain-community package\n",
        "\n",
        "### **FAISS vs Other Vector Databases:**\n",
        "While there are alternatives like Pinecone and ChromaDB, Faiss is an open-source library for the swift search of similarities and the clustering of dense vectors that's completely free and integrates seamlessly with LangChain.\n",
        "\n",
        "---\n",
        "\n",
        "##  **RAG (Retrieval-Augmented Generation)**\n",
        "\n",
        "### **What is RAG?**\n",
        "Retrieval-Augmented Generation (RAG) is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources before generating a response\n",
        "\n",
        "### **How RAG Works:**\n",
        "1. **User Query**: Person asks a question\n",
        "2. **Retrieval**: System searches knowledge base for relevant information\n",
        "3. **Augmentation**: The RAG model augments the user input (or prompts) by adding the relevant retrieved data in context\n",
        "4. **Generation**: LLM generates answer using both its training and retrieved information\n",
        "\n",
        "### **Why RAG is Revolutionary:**\n",
        "- **Up-to-date Information**: RAG extends the already powerful capabilities of LLMs to specific domains or an organization's internal knowledge base, all without the need to retrain the model\n",
        "- **Reduces Hallucinations**: Grounds responses in factual, retrieved data\n",
        "- **Cost-Effective**: It is a cost-effective approach to improving LLM output so it remains relevant, accurate, and useful in various contexts\n",
        "- **Domain-Specific Knowledge**: Add company-specific or specialized information\n",
        "\n",
        "### **RAG in 2025:**\n",
        "In 2025, advanced RAG systems address these and other limitations with a variety of innovations and architectural considerations. These enhancements push RAG from useful to indispensable\n",
        "\n",
        "**New RAG Capabilities:**\n",
        "- **Adaptive RAG**: Systems now dynamically adjust retrieval strategies based on query intent\n",
        "- **Multi-modal RAG**: Handle text, images, and other data types\n",
        "- **Self-Correcting RAG**: Systems that validate their own outputs\n",
        "\n",
        "---\n",
        "\n",
        "##  **Embeddings**\n",
        "\n",
        "### **What are Embeddings?**\n",
        "Technically, embeddings are vectors created by machine learning models for the purpose of capturing meaningful data about each object - they convert words, images, and other data into numbers that computers can understand and compare.\n",
        "\n",
        "### **How Embeddings Work:**\n",
        "Embeddings convert real-world objects into complex mathematical representations that capture inherent properties and relationships between real-world data\n",
        "\n",
        "**Simple Example:**\n",
        "- \"cat\" might become `[0.2, -0.4, 0.7]`\n",
        "- \"dog\" might become `[0.3, -0.5, 0.6]`\n",
        "- \"car\" might become `[0.8, 0.1, -0.2]`\n",
        "\n",
        "Notice how \"cat\" and \"dog\" are closer together (more similar) than either is to \"car\"!\n",
        "\n",
        "### **Why Embeddings Matter:**\n",
        "- **Semantic Understanding**: Since embeddings make it possible for computers to understand the relationships between words and other objects, they are foundational for artificial intelligence (AI)\n",
        "- **Similarity Search**: Essentially, embeddings enable machine learning models to find similar objects\n",
        "- **Foundation of Modern AI**: Vector embeddings thus underpin nearly all modern machine learning, powering models used in the fields of NLP and computer vision, and serving as the fundamental building blocks of generative AI\n",
        "\n",
        "### **Types of Embeddings:**\n",
        "- **Text Embeddings**: Convert words/sentences to vectors\n",
        "- **Image Embeddings**: Convert images to numerical representations\n",
        "- **Multimodal Embeddings**: Handle multiple data types together\n",
        "\n",
        "### **2025 State of Embeddings:**\n",
        "With the exception of OpenAI (whose text-embedding-3 models from March 2023 are ancient in light of the pace of AI progress), all the prominent commercial vector embedding vendors released a new version of their flagship models in late 2024 or early 2025\n",
        "\n",
        "---\n",
        "\n",
        "## üîó **How They Work Together in Your Chatbot**\n",
        "\n",
        "### **The Complete Pipeline:**\n",
        "\n",
        "1. **Knowledge Preparation** (Embeddings + FAISS):\n",
        "   - Convert your FAQ documents into embeddings (numerical vectors)\n",
        "   - Store these embeddings in FAISS for fast similarity search\n",
        "\n",
        "2. **User Query Processing** (RAG):\n",
        "   - User asks: \"What are your store hours?\"\n",
        "   - Convert question to embedding\n",
        "   - Use FAISS to find most similar FAQ items\n",
        "\n",
        "3. **Response Generation** (LangChain):\n",
        "   - LangChain retrieves relevant documents\n",
        "   - Adds mood/personality using system prompts\n",
        "   - Generates final response using LLM\n",
        "\n",
        "4. **Fun Response Mode**:\n",
        "   - Apply system prompt engineering for different personality modes\n",
        "   - Generate funny, mysterious, or serious versions of the same answer through prompt design\n",
        "\n",
        "### **Example Workflow:**\n",
        "```\n",
        "User: \"What are your store hours?\" (Mood: Funny)\n",
        "\n",
        "1. Embedding: [0.1, 0.8, 0.3, ...]\n",
        "2. FAISS Search: Finds \"We are open 9am‚Äì9pm, Mon‚ÄìSat\"\n",
        "3. RAG Retrieval: Gets store hours policy document\n",
        "4. LangChain + System Prompt: \"You are a witty assistant who loves humor.\n",
        "   Based on this context: 'We are open 9am‚Äì9pm, Mon‚ÄìSat'\n",
        "   Answer: What are your store hours?\"\n",
        "5. Response: \"We're open 9am-9pm Monday through Saturday!\n",
        "   We're like vampires - we come alive when the sun goes down,\n",
        "   but we still close at 9pm because even vampires need sleep!\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üí° **Why This Matters for Your Week 2 Project**\n",
        "\n",
        "### **Learning Objectives Achieved:**\n",
        "- **Prompt Engineering**: Using system prompts for personality and mood control\n",
        "- **Data Processing**: Understanding how text becomes searchable embeddings\n",
        "- **System Integration**: Seeing how multiple AI components work together\n",
        "- **Real-world Application**: Building something that could actually be deployed\n",
        "\n",
        "### **Technical Skills Developed:**\n",
        "- **Vector Databases**: Understanding modern data storage for AI\n",
        "- **Information Retrieval**: Learning how search engines really work\n",
        "- **AI Frameworks**: Hands-on experience with industry-standard tools\n",
        "- **API Integration**: Connecting different AI services together\n",
        "\n",
        "### **Industry Relevance:**\n",
        "These four technologies power virtually every AI application you use daily:\n",
        "- **ChatGPT**: Uses embeddings and retrieval techniques\n",
        "- **Google Search**: Employs vector similarity for results\n",
        "- **Recommendation Systems**: Netflix, Spotify use embeddings\n",
        "- **Customer Service Bots**: Built with LangChain + RAG architectures\n",
        "\n",
        "---\n",
        "\n",
        "## **Getting Started Tips**\n",
        "\n",
        "### **Installation Order:**\n",
        "1. **transformers** - For pre-trained AI models\n",
        "2. **langchain** - Main framework\n",
        "3. **langchain-community** - Additional integrations\n",
        "4. **sentence-transformers** - For creating embeddings\n",
        "5. **torch** - Deep learning backend\n",
        "6. **faiss-cpu** - Vector similarity search\n",
        "\n",
        "### **Best Practices:**\n",
        "- Start simple with basic RAG, then add complexity\n",
        "- Test each component individually before combining\n",
        "- Use small datasets while learning\n",
        "- Experiment with different embedding models\n",
        "- Design effective system prompts for different personality modes\n",
        "\n",
        "### **Common Pitfalls to Avoid:**\n",
        "- Don't try to implement everything at once\n",
        "- Make sure your embeddings model matches your language\n",
        "- Test with simple questions first\n",
        "- Keep system prompts clear and concise for consistent behavior\n",
        "\n",
        "---\n",
        "\n",
        "**Ready to build your Fun Response Mode Chatbot? These technologies will give you the foundation to create an AI assistant that's both intelligent and entertaining!** ‚ú®"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkXsfGwh7AAT"
      },
      "source": [
        "# Start Avtivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMXLNcnUzVCm"
      },
      "source": [
        "## Cell 1: Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WiUfxIBwmjLb",
        "outputId": "da8adc74-ccd5-45e1-f478-3ea7510691ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.75)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.23)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ],
      "source": [
        "# Install all required libraries for our chatbot project\n",
        "# Each library serves a specific purpose:\n",
        "\n",
        "%pip install __________          # For pre-trained AI models (BERT, DistilBERT, etc.)\n",
        "%pip install langchain             # Framework for building applications with language models\n",
        "%pip install langchain-community   # Community extensions for LangChain\n",
        "%pip install sentence-transformers # For creating text embeddings (converting text to numbers)\n",
        "%pip install  __________                 # PyTorch - deep learning framework (backend for transformers)\n",
        "%pip install faiss-cpu             # Facebook AI Similarity Search - for fast similarity searches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlIo91X4zP18"
      },
      "source": [
        "## Cell 2: Import Libraries and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_rAZzpGFmHUC"
      },
      "outputs": [],
      "source": [
        "# Import all the libraries we need for our chatbot\n",
        "\n",
        "# Import pipeline from transformers - this gives us easy access to pre-trained models\n",
        "from transformers import pipeline\n",
        "\n",
        "# Import FAISS for creating a searchable database of text\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Import embeddings to convert text into numerical vectors for similarity search\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Import Document class to structure our knowledge data\n",
        "from langchain.docstore.document import Document\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAcS6yx20TCP"
      },
      "source": [
        "## Cell 3: Setup Knowledge Base and QA Pipelin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OklX2uQ-mL4T"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Define knowledge base ---\n",
        "# Create a simple knowledge base with question-answer pairs\n",
        "# This is like creating a mini-encyclopedia for our chatbot\n",
        "faq_data = [\n",
        "    (\"What is Python?\", \"Python is a high-level programming language known for its simplicity and readability.\"),\n",
        "    (\"What is machine learning?\", \"Machine learning is a subset of AI that enables computers to learn without being explicitly programmed.\"),\n",
        "    (\"What is a chatbot?\", \"A chatbot is a computer program designed to simulate conversation with human users.\"),\n",
        "    (\"What is the return policy?\", \"30 days return with full refund.\"),\n",
        "    (\"What are your store hours?\", \"We are open 9am‚Äì9pm, Mon‚ÄìSat.\"),\n",
        "    (\"Do you ship internationally?\", \"Yes, we ship worldwide, including Australia.\")\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlNRrDzv2P_p"
      },
      "source": [
        "## Cell 4: Convert Knowledge base into LangChain Document objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kzoi3IT-naMG"
      },
      "outputs": [],
      "source": [
        "# --- Step 2: Convert our FAQ data into LangChain Document objects ---\n",
        "# Each document contains both the question and answer as searchable content\n",
        "# List comprehension: [expression for item in list] creates a new list\n",
        "documents = [Document(page_content=qa[0] + \" \" + qa[1]) for qa in faq_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwFO2H9J7w85"
      },
      "source": [
        "## Cell 5: Create embeddings model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wPJW_oJe2jfg"
      },
      "outputs": [],
      "source": [
        "# --- Step 3:  Create embeddings model - this converts text into numerical vectors ---\n",
        "# We use a pre-trained model that's good at understanding sentence meanings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Here is a larger model\n",
        "# embeddings = HuggingFaceEmbeddings(model_name=\"gasolsun/DynamicRAG-8B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-8R9lSy79O9"
      },
      "source": [
        "## Cell 6: Create a FAISS database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mnOtFO572mvf"
      },
      "outputs": [],
      "source": [
        "# --- Step 4:  Create a FAISS database from our documents (FAISS index)\n",
        "# FAISS allows us to quickly find the most relevant documents for any question\n",
        "db = FAISS.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOsHDyr48IOY"
      },
      "source": [
        "## Cell 7: Load a pre-trained question-answering model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "79429f9c26bf4f259eda89076039e1ee",
            "e987e9488d2642b6a0c5b15c99a159e3",
            "dff9a443018249759cc5d7e126539eb1",
            "841eb98c406142cc85ca43c202bf0c56",
            "b50db6fd72124eb991920d66630ffb29",
            "44d723d866c3420cab8de2f8aba9932e",
            "722086aa990f41e99c2c755c814440fa",
            "a0cce7ae002f425f8fdfdaf01bb81a65",
            "d57d78dd625c4ac78a7f5be13a8e58ad",
            "a88c0021d359464aaa321f19f6d9a8a4",
            "ef757f065a064047b6ca3622f33a72de",
            "d031a2bc6a364315b506a17314add1ca",
            "4cb3628677ed4943814a33d949bffd22",
            "f0ecd3d7a1034edaae33e39e77c9c5d1",
            "6e345a83465846ed8b563b99ec91f4fa",
            "879611cee67040ab8f5c05bfb4d0f1e2",
            "547f40a0596a42238692cbcbb4f71217",
            "4acc4a63a29f4cbb95a390298b9fc80e",
            "269a18151a2143c6b4a16e5162bf48e7",
            "46026dcd9cec416eb338c912e2988249",
            "adc96398dfde414cab47ac4ef747cdfc",
            "264b9ba492c94a909671c2f723885c8f",
            "989bfeb3f6ed4fe8b6cb8f058393dd2c",
            "f861f652b90b421fb64b2f32e1b9cb5c",
            "ffc951e68a2d4ba3a9dd37179d544896",
            "b3ffcf98d287474fb309ccdb27ed06b2",
            "52a4c3bb579841c6bc95994b6bd5b145",
            "3612bcc251af4abcaa00ffac2065447b",
            "bfc08fb5e40f4203bc42934fa2422e1d",
            "6839db3a338343478a99283adc1b67ee",
            "d3d6ec3b9f7d496285afa68c0f45deb9",
            "8e804bd15b8e4f47bec86ab984e259d3",
            "2e72a6cee8964ae6a5c6fa35640c7256"
          ]
        },
        "id": "gWunMKJJ2rVn",
        "outputId": "18f9cbf2-96f1-4c0f-de9b-8b7b1609bc38"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79429f9c26bf4f259eda89076039e1ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d031a2bc6a364315b506a17314add1ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "989bfeb3f6ed4fe8b6cb8f058393dd2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Knowledge base and QA pipeline loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# --- Step 5:  Load a pre-trained question-answering model ---\n",
        "# DistilBERT is a smaller, faster version of BERT that's good for Q&A tasks\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "\"\"\"Additional models from HugginFace\"\"\"\n",
        "# qa_pipeline = pipeline(\"question-answering\", model=\"consciousAI/question-answering-generative-t5-v1-base-s-q-c\")\n",
        "# qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "# qa_pipeline = pipeline(\"question-answering\", model=\"google-bert/bert-large-cased-whole-word-masking-finetuned-squad\")\n",
        "# qa_pipeline = pipeline(\"question-answering\", model=\"gasolsun/DynamicRAG-8B\")\n",
        "print(\"Knowledge base and QA pipeline loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BagFdclu8_uV"
      },
      "source": [
        "## Cell 8: Create Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HtzGL4pimUzH"
      },
      "outputs": [],
      "source": [
        "# --- Step 6: Ask questions ---\n",
        "questions = [\n",
        "    \"Can I return a product after 2 weeks?\",\n",
        "    \"Do you ship to Australia?\",\n",
        "    \"What time do you open on Monday?\",\n",
        "    \"Do you sell electronics?\",\n",
        "    \"what is python\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp9o2pblloIc",
        "outputId": "3fcfb498-2ff9-4d31-f8f2-ddde5fbda3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Week 2 Chatbot Response ---\n",
            "\n",
            "Q: Can I return a product after 2 weeks?\n",
            "A: I don't know.\n",
            "\n",
            "Q: Do you ship to Australia?\n",
            "A: I don't know.\n",
            "\n",
            "Q: What time do you open on Monday?\n",
            "A: 9am‚Äì9pm\n",
            "\n",
            "Q: Do you sell electronics?\n",
            "A: I don't know.\n",
            "\n",
            "Q: what is python\n",
            "A: a high-level programming language\n"
          ]
        }
      ],
      "source": [
        "# print(\"\\n--- Week 2 Chatbot Response ---\")\n",
        "# for q in questions:\n",
        "#     # Retrieve most relevant FAQ context\n",
        "#     docs = db.similarity_search(q, k=2)\n",
        "#     context = \" \".join([d.page_content for d in docs])\n",
        "\n",
        "#     # Run QA model properly\n",
        "#     result = qa_pipeline({\"question\": q, \"context\": context})\n",
        "\n",
        "#     # If confidence is low ‚Üí fallback \"I don't know\"\n",
        "#     answer = result[\"answer\"] if result[\"score\"] > 0.2 else \"I don't know.\"\n",
        "\n",
        "#     print(f\"\\nQ: {q}\\nA: {answer}\")\n",
        "\n",
        "\n",
        "# Print a header to clearly separate this section of output\n",
        "print(\"\\n--- Week 2 Chatbot Response ---\")\n",
        "\n",
        "# Loop through each question in the questions list\n",
        "for q in questions:\n",
        "\n",
        "    # STEP 1: FIND RELEVANT INFORMATION\n",
        "    # Use FAISS similarity search to find the 2 most relevant FAQ documents\n",
        "    # 'db' is our FAISS vector database containing embedded FAQ data\n",
        "    # 'k=2' means \"return the top 2 most similar documents\"\n",
        "    docs = db.similarity_search(q, k=2)\n",
        "\n",
        "    # STEP 2: PREPARE CONTEXT FOR THE AI MODEL\n",
        "    # Combine the content from retrieved documents into one text string\n",
        "    # This creates the \"context\" that will help the QA model answer accurately\n",
        "    # Each 'd.page_content' contains the text from a retrieved FAQ document\n",
        "    context = \" \".join([d.page_content for d in docs])\n",
        "\n",
        "    # STEP 3: GENERATE ANSWER USING QA MODEL\n",
        "    # Pass both the user's question AND the retrieved context to the QA pipeline\n",
        "    # The model will use the context to generate a more accurate, grounded answer\n",
        "    # This is the \"Augmented\" part of Retrieval-Augmented Generation (RAG)\n",
        "    result = qa_pipeline({\"question\": q, \"context\": context})\n",
        "\n",
        "    # STEP 4: CONFIDENCE-BASED ANSWER SELECTION\n",
        "    # Check if the model is confident enough in its answer (score > 0.2)\n",
        "    # If confidence is too low, use a safe fallback response\n",
        "    # This prevents the chatbot from giving unreliable or hallucinated answers\n",
        "    answer = result[\"answer\"] if result[\"score\"] > 0.2 else \"I don't know.\"\n",
        "\n",
        "    # STEP 5: DISPLAY RESULTS\n",
        "    # Format and print the question-answer pair for easy reading\n",
        "    # \\n creates line breaks for better formatting\n",
        "    print(f\"\\nQ: {q}\\nA: {answer}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdIEWhX7qQwg"
      },
      "source": [
        "# Class Activity: RAG-Based Question Answering System with Mistral\n",
        "---\n",
        "\n",
        "### Class Activity: Building an Intelligent Q&A System with FAISS and Mistral\n",
        "\n",
        "**Objective:** Students will design and implement a Retrieval-Augmented Generation (RAG) system using Mistral-7B-Instruct, FAISS vector database, and custom business data.\n",
        "\n",
        "**Submission:** Submit the link to your completed notebook.\n",
        "\n",
        "---\n",
        "\n",
        "## **Instructions:**\n",
        "\n",
        "### **1. Create an Assistant System Prompt**\n",
        "* Using `mistralai/Mistral-7B-Instruct-v0.3`, design a system prompt that gives the model a specific role\n",
        "* Examples: \"You are a marketing expert for a tech startup\" or \"You are a database creator for a healthcare organization\"\n",
        "* Choose a specific organization/business context you'll work with throughout this activity\n",
        "\n",
        "### **2. Generate Business Database Content**\n",
        "* Use `mistralai/Mistral-7B-Instruct-v0.3` from Hugging Face to create prompts that generate:\n",
        "  - A comprehensive Q&A database for your chosen business/organization\n",
        "  - Minimum 10-15 question-answer pairs covering different aspects of the business\n",
        "* **Add comments in your notebook clearly showing the new database Q&A pairs**\n",
        "\n",
        "### **3. Implement FAISS Vector Database**\n",
        "* Convert your generated Q&A database into embeddings\n",
        "* Store the embeddings in a FAISS index for efficient similarity search\n",
        "* **Use comments to demonstrate the database implementation process**\n",
        "\n",
        "### **4. Create Test Questions**\n",
        "* Using `mistralai/Mistral-7B-Instruct-v0.3`, generate two types of questions:\n",
        "  - **Answerable questions**: Can be directly answered from your database\n",
        "  - **Unanswerable questions**: Require information not present in your database\n",
        "* Create at least 5 questions of each type\n",
        "\n",
        "### **5. Implement and Test Questions**\n",
        "* Run both types of questions through your RAG system\n",
        "* **Use clear comments to differentiate between:**\n",
        "  - Questions that can be answered (with expected good retrieval)\n",
        "  - Questions that cannot be answered (testing system limitations)\n",
        "\n",
        "### **6. Model Experimentation and Ranking**\n",
        "* Test your RAG system with multiple Q&A models from Hugging Face\n",
        "* **Experiment with these specific QA models and include two additional models of your choice:**\n",
        "\n",
        "```python\n",
        "\"\"\"Required models to test\"\"\"\n",
        "# Experiment with these QA models:\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"consciousAI/question-answering-generative-t5-v1-base-s-q-c\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"google-bert/bert-large-cased-whole-word-masking-finetuned-squad\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"gasolsun/DynamicRAG-8B\")\n",
        "\n",
        "\"\"\"Additional models from HuggingFace\"\"\"\n",
        "# Add two more QA models of your choice from Hugging Face\n",
        "# Example options: distilbert-base-cased-distilled-squad, microsoft/DialoGPT-medium, etc.\n",
        "\n",
        "print(\"Knowledge base and QA pipeline loaded successfully!\")\n",
        "```\n",
        "\n",
        "* **Test all models with both answerable and unanswerable questions**\n",
        "* **Rank the models from best to worst performance and explain why**\n",
        "* **Identify which model(s) provide confidence scores but still show reasonable output**\n",
        "* **Compare performance across different question types (factual, reasoning, out-of-scope)**\n",
        "\n",
        "#### **Model Evaluation Criteria:**\n",
        "- **Accuracy**: How well does it answer questions from your database?\n",
        "- **Confidence Handling**: Does it appropriately indicate uncertainty for unanswerable questions?\n",
        "- **Response Quality**: Are the answers coherent and relevant?\n",
        "- **Speed**: How fast does each model process queries?\n",
        "- **Robustness**: How does it handle edge cases and out-of-scope questions?\n",
        "\n",
        "---\n",
        "\n",
        "## **Technical Requirements:**\n",
        "\n",
        "### **Installation:**\n",
        "```python\n",
        "# Required packages\n",
        "%pip install transformers torch sentence-transformers faiss-cpu langchain\n",
        "```\n",
        "\n",
        "### **Key Components to Include:**\n",
        "1. **System Prompt Design** - Clear agentic role definition\n",
        "2. **Database Generation** - Mistral-generated business Q&A pairs  \n",
        "3. **FAISS Implementation** - Vector storage and retrieval\n",
        "4. **Question Testing** - Both answerable and unanswerable queries\n",
        "5. **Model Comparison** - Performance analysis and ranking\n",
        "6. **Confidence Analysis** - Model uncertainty vs. output quality\n",
        "\n",
        "---\n",
        "\n",
        "## **Deliverables:**\n",
        "\n",
        "Your notebook should demonstrate:\n",
        "\n",
        "* **Business Context**: Clear organization/role you've chosen\n",
        "* **Generated Database**: Commented Q&A pairs created by Mistral\n",
        "* **FAISS Integration**: Working vector database implementation\n",
        "* **Question Analysis**: Clear separation of answerable vs. unanswerable questions\n",
        "* **Model Evaluation**: Ranked comparison of different Q&A models\n",
        "* **Performance Insights**: Analysis of confidence scores and output quality\n",
        "* **Reflection**: Strengths, weaknesses, and real-world applications\n",
        "\n",
        "---\n",
        "\n",
        "## **Evaluation Criteria:**\n",
        "\n",
        "* **Creativity** in business context and agentic role design\n",
        "* **Technical Implementation** of RAG pipeline with FAISS\n",
        "* **Quality Analysis** of different Q&A models\n",
        "* **Clear Documentation** with meaningful comments\n",
        "* **Critical Thinking** in model comparison and limitations analysis\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** Focus on building a system that could realistically be deployed for a real business use case. Consider scalability, accuracy, and user experience in your implementation choices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PkXT87_DnzCK"
      },
      "outputs": [],
      "source": [
        "# # Check if GPU is available and set device accordingly\n",
        "# if torch.cuda.is_available():\n",
        "#     device = 0  # Use GPU\n",
        "#     print(\"GPU detected - Using GPU for faster processing\")\n",
        "# else:\n",
        "#     device = -1  # Use CPU\n",
        "#     print(\"GPU not available - Using CPU\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "264b9ba492c94a909671c2f723885c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "269a18151a2143c6b4a16e5162bf48e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e72a6cee8964ae6a5c6fa35640c7256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3612bcc251af4abcaa00ffac2065447b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d723d866c3420cab8de2f8aba9932e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46026dcd9cec416eb338c912e2988249": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4acc4a63a29f4cbb95a390298b9fc80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cb3628677ed4943814a33d949bffd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547f40a0596a42238692cbcbb4f71217",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4acc4a63a29f4cbb95a390298b9fc80e",
            "value": "Fetching‚Äá1‚Äáfiles:‚Äá100%"
          }
        },
        "52a4c3bb579841c6bc95994b6bd5b145": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547f40a0596a42238692cbcbb4f71217": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6839db3a338343478a99283adc1b67ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6e345a83465846ed8b563b99ec91f4fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc96398dfde414cab47ac4ef747cdfc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_264b9ba492c94a909671c2f723885c8f",
            "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá133.90it/s]"
          }
        },
        "722086aa990f41e99c2c755c814440fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79429f9c26bf4f259eda89076039e1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e987e9488d2642b6a0c5b15c99a159e3",
              "IPY_MODEL_dff9a443018249759cc5d7e126539eb1",
              "IPY_MODEL_841eb98c406142cc85ca43c202bf0c56"
            ],
            "layout": "IPY_MODEL_b50db6fd72124eb991920d66630ffb29"
          }
        },
        "841eb98c406142cc85ca43c202bf0c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a88c0021d359464aaa321f19f6d9a8a4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ef757f065a064047b6ca3622f33a72de",
            "value": "‚Äá0/0‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "879611cee67040ab8f5c05bfb4d0f1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e804bd15b8e4f47bec86ab984e259d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "989bfeb3f6ed4fe8b6cb8f058393dd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f861f652b90b421fb64b2f32e1b9cb5c",
              "IPY_MODEL_ffc951e68a2d4ba3a9dd37179d544896",
              "IPY_MODEL_b3ffcf98d287474fb309ccdb27ed06b2"
            ],
            "layout": "IPY_MODEL_52a4c3bb579841c6bc95994b6bd5b145"
          }
        },
        "a0cce7ae002f425f8fdfdaf01bb81a65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a88c0021d359464aaa321f19f6d9a8a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc96398dfde414cab47ac4ef747cdfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ffcf98d287474fb309ccdb27ed06b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e804bd15b8e4f47bec86ab984e259d3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2e72a6cee8964ae6a5c6fa35640c7256",
            "value": "‚Äá0/0‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "b50db6fd72124eb991920d66630ffb29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc08fb5e40f4203bc42934fa2422e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d031a2bc6a364315b506a17314add1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cb3628677ed4943814a33d949bffd22",
              "IPY_MODEL_f0ecd3d7a1034edaae33e39e77c9c5d1",
              "IPY_MODEL_6e345a83465846ed8b563b99ec91f4fa"
            ],
            "layout": "IPY_MODEL_879611cee67040ab8f5c05bfb4d0f1e2"
          }
        },
        "d3d6ec3b9f7d496285afa68c0f45deb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d57d78dd625c4ac78a7f5be13a8e58ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dff9a443018249759cc5d7e126539eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0cce7ae002f425f8fdfdaf01bb81a65",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d57d78dd625c4ac78a7f5be13a8e58ad",
            "value": 0
          }
        },
        "e987e9488d2642b6a0c5b15c99a159e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44d723d866c3420cab8de2f8aba9932e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_722086aa990f41e99c2c755c814440fa",
            "value": "Fetching‚Äá0‚Äáfiles:‚Äá"
          }
        },
        "ef757f065a064047b6ca3622f33a72de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0ecd3d7a1034edaae33e39e77c9c5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269a18151a2143c6b4a16e5162bf48e7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46026dcd9cec416eb338c912e2988249",
            "value": 1
          }
        },
        "f861f652b90b421fb64b2f32e1b9cb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3612bcc251af4abcaa00ffac2065447b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bfc08fb5e40f4203bc42934fa2422e1d",
            "value": "Fetching‚Äá0‚Äáfiles:‚Äá"
          }
        },
        "ffc951e68a2d4ba3a9dd37179d544896": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6839db3a338343478a99283adc1b67ee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3d6ec3b9f7d496285afa68c0f45deb9",
            "value": 0
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
