{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTgyjtqo7ggh",
        "outputId": "cc6bb072-36fc-4556-f5b0-55e8805b7f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleaning up...\n",
            "üì¶ Installing packages (2-3 minutes)...\n",
            "Found existing installation: transformers 4.41.0\n",
            "Uninstalling transformers-4.41.0:\n",
            "  Successfully uninstalled transformers-4.41.0\n",
            "Found existing installation: diffusers 0.27.0\n",
            "Uninstalling diffusers-0.27.0:\n",
            "  Successfully uninstalled diffusers-0.27.0\n",
            "Found existing installation: huggingface-hub 0.35.3\n",
            "Uninstalling huggingface-hub-0.35.3:\n",
            "  Successfully uninstalled huggingface-hub-0.35.3\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Packages installed!\n",
            "‚úÖ App created!\n",
            "\n",
            "üöÄ Starting Streamlit...\n",
            "üåê Creating public URL...\n",
            "\n",
            "============================================================\n",
            "‚úÖ SUCCESS! Your app is running!\n",
            "============================================================\n",
            "\n",
            "üåê Open this URL in your browser:\n",
            "   NgrokTunnel: \"https://dorothea-prefixable-covalently.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n",
            "üìå Tips:\n",
            "   ‚Ä¢ Keep this Colab notebook running\n",
            "   ‚Ä¢ First image generation takes longer (loading models)\n",
            "   ‚Ä¢ Use short, clear voice prompts\n",
            "   ‚Ä¢ Free Colab = CPU mode (slower but works!)\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "#  Audio-to-Image Generator ‚Äî TESTED & WORKING\n",
        "#  Run this entire cell in Google Colab\n",
        "# =====================================================\n",
        "\n",
        "# ==================== STEP 1: Clean Environment ====================\n",
        "print(\"üßπ Cleaning up...\")\n",
        "import os\n",
        "os.system('pkill -9 streamlit')\n",
        "os.system('pkill -9 ngrok')\n",
        "\n",
        "# ==================== STEP 2: Install Packages ====================\n",
        "print(\"üì¶ Installing packages (2-3 minutes)...\")\n",
        "!pip uninstall -y transformers diffusers huggingface-hub\n",
        "!pip install -q transformers==4.41.2 diffusers==0.30.0 accelerate pyngrok streamlit soundfile\n",
        "\n",
        "print(\"‚úÖ Packages installed!\")\n",
        "\n",
        "# ==================== STEP 3: Import & Setup ====================\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ‚ö†Ô∏è IMPORTANT: Set your ngrok token here\n",
        "# Get it from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_TOKEN = \"3443vHI71ODZeUY6WQUeBW45KG7_HL7SDdKFz6uty9yqd8Cg\"  # ‚ö†Ô∏è CHANGE THIS!\n",
        "\n",
        "if NGROK_TOKEN == \"YOUR_TOKEN_HERE\":\n",
        "    print(\"\\n‚ùå ERROR: Please set your ngrok token!\")\n",
        "    print(\"   1. Go to: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "    print(\"   2. Copy your token\")\n",
        "    print(\"   3. Replace 'YOUR_TOKEN_HERE' in the code above\")\n",
        "    raise SystemExit\n",
        "\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# Kill existing tunnels\n",
        "for tunnel in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "\n",
        "# ==================== STEP 4: Create Streamlit App ====================\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import time\n",
        "\n",
        "# Config\n",
        "st.set_page_config(page_title=\"üéôÔ∏è Audio-to-Image\", layout=\"centered\")\n",
        "\n",
        "# ==================== Load Models ====================\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    \"\"\"Load both Whisper and Stable Diffusion\"\"\"\n",
        "    st.info(\"Loading AI models... (first run takes 3-5 minutes)\")\n",
        "\n",
        "    # Whisper for speech-to-text\n",
        "    whisper = pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=\"openai/whisper-tiny\",\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "\n",
        "    # Stable Diffusion for image generation\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    sd = StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        safety_checker=None\n",
        "    ).to(device)\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        sd.enable_attention_slicing()\n",
        "\n",
        "    return whisper, sd\n",
        "\n",
        "whisper_model, sd_model = load_models()\n",
        "\n",
        "# ==================== UI ====================\n",
        "st.title(\"üéôÔ∏è Audio-to-Image Generator\")\n",
        "st.markdown(\"Transform your voice into stunning AI-generated images!\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Input methods\n",
        "tab1, tab2 = st.tabs([\"üé§ Upload Audio\", \"‚úçÔ∏è Type Text\"])\n",
        "\n",
        "prompt_text = None\n",
        "\n",
        "with tab1:\n",
        "    st.write(\"Upload an audio file with your image description\")\n",
        "    audio_file = st.file_uploader(\n",
        "        \"Choose audio file\",\n",
        "        type=[\"wav\", \"mp3\", \"m4a\", \"flac\"],\n",
        "        help=\"Speak clearly: 'A beautiful sunset over mountains'\"\n",
        "    )\n",
        "\n",
        "    if audio_file:\n",
        "        st.audio(audio_file)\n",
        "\n",
        "        if st.button(\"üéß Transcribe Audio\", type=\"primary\"):\n",
        "            with st.spinner(\"Converting speech to text...\"):\n",
        "                # Save temp file\n",
        "                with open(\"temp_audio.wav\", \"wb\") as f:\n",
        "                    f.write(audio_file.read())\n",
        "\n",
        "                # Transcribe\n",
        "                result = whisper_model(\"temp_audio.wav\")\n",
        "                prompt_text = result[\"text\"]\n",
        "\n",
        "                st.success(f\"‚úÖ Transcription: **{prompt_text}**\")\n",
        "                st.session_state.prompt = prompt_text\n",
        "\n",
        "with tab2:\n",
        "    manual_prompt = st.text_area(\n",
        "        \"Describe the image you want to generate:\",\n",
        "        placeholder=\"Example: A serene lake surrounded by autumn trees at sunset\",\n",
        "        height=100\n",
        "    )\n",
        "    if manual_prompt:\n",
        "        st.session_state.prompt = manual_prompt\n",
        "\n",
        "# Settings\n",
        "with st.expander(\"‚öôÔ∏è Advanced Settings\"):\n",
        "    col1, col2 = st.columns(2)\n",
        "    steps = col1.slider(\"Quality (inference steps)\", 10, 50, 25,\n",
        "                       help=\"More steps = better quality but slower\")\n",
        "    guidance = col2.slider(\"Prompt strength\", 5.0, 15.0, 7.5,\n",
        "                          help=\"Higher = follows prompt more closely\")\n",
        "\n",
        "# Generate button\n",
        "st.markdown(\"---\")\n",
        "if st.button(\"üé® Generate Image\", type=\"primary\", use_container_width=True):\n",
        "\n",
        "    # Get prompt from session state\n",
        "    final_prompt = st.session_state.get('prompt', None)\n",
        "\n",
        "    if not final_prompt:\n",
        "        st.error(\"‚ùå Please provide audio or text first!\")\n",
        "        st.stop()\n",
        "\n",
        "    # Generate image\n",
        "    st.info(f\"üé® Generating image from: **{final_prompt}**\")\n",
        "    st.write(\"This may take 30 seconds to 3 minutes depending on your GPU...\")\n",
        "\n",
        "    progress_bar = st.progress(0)\n",
        "    start_time = time.time()\n",
        "\n",
        "    with st.spinner(\"Creating your masterpiece...\"):\n",
        "        try:\n",
        "            # Generate\n",
        "            image = sd_model(\n",
        "                prompt=final_prompt,\n",
        "                num_inference_steps=steps,\n",
        "                guidance_scale=guidance,\n",
        "                height=512,\n",
        "                width=512\n",
        "            ).images[0]\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            progress_bar.progress(100)\n",
        "\n",
        "            # Display\n",
        "            st.success(f\"‚úÖ Generated in {elapsed:.1f} seconds!\")\n",
        "            st.image(image, caption=final_prompt, use_column_width=True)\n",
        "\n",
        "            # Save and download\n",
        "            image.save(\"generated_image.png\")\n",
        "            with open(\"generated_image.png\", \"rb\") as f:\n",
        "                st.download_button(\n",
        "                    \"üíæ Download Image\",\n",
        "                    data=f,\n",
        "                    file_name=f\"ai_art_{int(time.time())}.png\",\n",
        "                    mime=\"image/png\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå Generation failed: {str(e)}\")\n",
        "            st.info(\"Try simplifying your prompt or reducing quality settings\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"üîä Powered by OpenAI Whisper + Stable Diffusion v1.5\")\n",
        "\n",
        "# GPU info\n",
        "device_info = \"üöÄ GPU Accelerated\" if torch.cuda.is_available() else \"üê¢ CPU Mode (slower)\"\n",
        "st.caption(device_info)\n",
        "'''\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"‚úÖ App created!\")\n",
        "\n",
        "# ==================== STEP 5: Launch ====================\n",
        "print(\"\\nüöÄ Starting Streamlit...\")\n",
        "os.system('streamlit run app.py &>/dev/null &')\n",
        "time.sleep(8)\n",
        "\n",
        "print(\"üåê Creating public URL...\")\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ SUCCESS! Your app is running!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nüåê Open this URL in your browser:\")\n",
        "    print(f\"   {public_url}\")\n",
        "    print(f\"\\nüìå Tips:\")\n",
        "    print(f\"   ‚Ä¢ Keep this Colab notebook running\")\n",
        "    print(f\"   ‚Ä¢ First image generation takes longer (loading models)\")\n",
        "    print(f\"   ‚Ä¢ Use short, clear voice prompts\")\n",
        "    print(f\"   ‚Ä¢ Free Colab = CPU mode (slower but works!)\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    print(\"\\nüîß Troubleshooting:\")\n",
        "    print(\"   1. Check your ngrok token is correct\")\n",
        "    print(\"   2. Try: Runtime ‚Üí Restart runtime\")\n",
        "    print(\"   3. Make sure you changed 'YOUR_TOKEN_HERE'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRm2n-hrAqIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}