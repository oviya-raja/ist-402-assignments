{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System Exercise - Building a Complete RAG System with Mistral\n",
    "\n",
    "**IST402 - AI Agents & RAG Systems**\n",
    "\n",
    "This notebook implements a complete RAG (Retrieval-Augmented Generation) system following the class exercise requirements:\n",
    "\n",
    "- **Step 1**: Create business-specific system prompts\n",
    "- **Step 2**: Generate Q&A database using Mistral\n",
    "- **Step 3**: Implement FAISS vector database for similarity search\n",
    "- **Step 4**: Create test questions (answerable and unanswerable)\n",
    "- **Step 5**: Test RAG system performance\n",
    "- **Step 6**: Evaluate and rank multiple QA models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from typing import Dict, Tuple, List, Any, Optional\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*weights.*not initialized.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*You should probably TRAIN.*\")\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, logging as transformers_logging\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import faiss\n",
    "    transformers_logging.set_verbosity_error()\n",
    "    print(\"‚úÖ All required libraries imported successfully!\")\n",
    "except (ImportError, RuntimeError) as e:\n",
    "    error_msg = str(e)\n",
    "    if \"register_fake\" in error_msg or \"torch.library\" in error_msg:\n",
    "        print(\"‚ùå Dependency version mismatch! Run: pip install --upgrade torch torchvision\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {error_msg}\")\n",
    "        print(\"Install with: pip install transformers torch sentence-transformers faiss-cpu\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "EMBEDDING_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "BUSINESS_NAME = \"TechStart Solutions\"\n",
    "ROLE = \"AI Solutions Consultant\"\n",
    "\n",
    "QA_MODELS = [\n",
    "    \"consciousAI/question-answering-generative-t5-v1-base-s-q-c\",\n",
    "    \"deepset/roberta-base-squad2\",\n",
    "    \"google-bert/bert-large-cased-whole-word-masking-finetuned-squad\",\n",
    "    \"gasolsun/DynamicRAG-8B\",\n",
    "    \"distilbert-base-uncased-distilled-squad\",\n",
    "    \"mrm8488/bert-tiny-finetuned-squadv2\",\n",
    "]\n",
    "\n",
    "print(f\"üìã Business: {BUSINESS_NAME}\")\n",
    "print(f\"üìã Role: {ROLE}\")\n",
    "print(f\"‚úÖ Configured {len(QA_MODELS)} QA models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is organized step-by-step for clarity and learning. Run all cells in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Detection & Configuration\n",
    "\n",
    "Automatically detect if GPU is available and configure accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Get Hugging Face token from environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mistral Model\n",
    "\n",
    "Load the Mistral model for generating Q&A pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# STEP 1: Create System Prompt\n",
    "\n",
    "Create a system prompt that defines the AI's role and expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# STEP 2: Generate Q&A Database\n",
    "\n",
    "Use Mistral to generate Q&A pairs (7 answerable + 7 unanswerable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# STEP 3: Implement FAISS Vector Database\n",
    "\n",
    "Convert Q&A database into embeddings and create FAISS index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# STEP 4: Create Test Questions\n",
    "\n",
    "Generate test questions (answerable and unanswerable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# STEP 5: Test RAG System\n",
    "\n",
    "Test the RAG system with both question types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# STEP 6: Model Experimentation and Ranking\n",
    "\n",
    "Test and rank multiple QA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Step 1\n",
    "system_prompt = create_system_prompt(BUSINESS_NAME, ROLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Step 2: Load Mistral and generate Q&A\n",
    "device_config = get_device_configuration()\n",
    "hf_token = setup_token()\n",
    "model, tokenizer = load_mistral_model(MISTRAL_MODEL_ID, hf_token, device_config)\n",
    "chatbot = create_mistral_pipeline(model, tokenizer, device_config)\n",
    "answerable_qa, unanswerable_qa = generate_qa_database(chatbot, system_prompt, BUSINESS_NAME)\n",
    "qa_database = answerable_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Step 3\n",
    "embedding_model, faiss_index = implement_faiss_database(qa_database, hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Step 4\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4: Preparing Test Questions\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìö Using unanswerable pairs from Step 2 as test questions\")\n",
    "print(f\"   Unanswerable test questions: {len(unanswerable_qa)}\")\n",
    "print(\"\\nüìö Generating additional answerable test questions...\")\n",
    "additional_answerable = generate_test_questions(chatbot, system_prompt, \"answerable\", BUSINESS_NAME)\n",
    "answerable = [qa[\"question\"] for qa in answerable_qa[:5]] + additional_answerable[:2]\n",
    "unanswerable = [qa[\"question\"] for qa in unanswerable_qa[:7]]\n",
    "print(f\"   Answerable test questions: {len(answerable)}\")\n",
    "print(f\"   Unanswerable test questions: {len(unanswerable)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Step 5\n",
    "implement_and_test_questions(answerable, unanswerable, embedding_model, faiss_index, qa_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Step 6\n",
    "test_questions = [qa[\"question\"] for qa in answerable_qa[:5]]\n",
    "model_rankings = rank_qa_models(qa_database, embedding_model, faiss_index, hf_token, test_questions=test_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Exercise Completed!\n",
    "\n",
    "You have successfully built a complete RAG system with:\n",
    "- System prompt creation\n",
    "- Q&A database generation\n",
    "- FAISS vector database\n",
    "- Test question generation\n",
    "- RAG system testing\n",
    "- QA model evaluation and ranking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
